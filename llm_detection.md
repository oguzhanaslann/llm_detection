# LLM Detection Guide

## Overview
The goal is to detect whether text was generated by a Large Language Model (LLM) or written by a human. This capability is crucial for maintaining content authenticity and academic integrity.

## Current State of Detection

### Theoretical Basis
- AI models create distinct statistical patterns different from human writing
- These differences become more pronounced in longer texts
- Detection should be theoretically possible due to AI's specific training data and algorithms
- Text generated by larger language models becomes increasingly difficult to detect due to more human-like patterns

### Detection Methods

#### 1. Linguistic Analysis [blackbox]
- Perplexity Analysis:
  - Measures how well a model predicts a sentence
  - Lower perplexity typically indicates AI-generated content
  - Higher perplexity suggests human authorship
  - Limitation: Can't compute prediction perplexity without ground truth labels

- Burstiness Analysis:
  - Quantifies variation in complexity across text segments
  - Human text shows natural variations
  - AI text tends to be more consistent

- N-gram Analysis:
  - Examines sequences of words for pattern detection
  - Identifies patterns common in AI but rare in human writing
  - Used in statistical fingerprinting

- Syntactic Analysis:
  - Analyzes sentence structure and grammar
  - Identifies AI-specific patterns
  - Checks for consistency in writing style

#### 2. Watermarking [whitebox]
- Types:
  - Post-hoc: Inserts hidden verification messages
  - Inference time: Alters word selection during generation
- Implementation:
  - Uses "green" and "red" token lists for sampling
  - Requires careful balance between detection strength and false positives
- Limitations:
  - Requires access to the original LLM
  - Relies on a secret key
  - Strong watermarking leads to false positives
  - Weak watermarking easily bypassed by paraphrasing

#### 3. Machine Learning Based Detection [blackbox]
- Fine-tuned LM Detectors:
  - Uses fine-tuning and contrastive learning
  - Trains on both human and AI-generated content
  - BERT/RoBERTa-based approaches:
    - Achieves up to 95% accuracy in detecting LLM-generated text
    - Strong performance even with limited training data
    - Effective for both sentence-level (98.43% F1) and paragraph-level (99.79% F1) detection
    - Limitations include overfitting and cross-domain generalization
    - Can be enhanced by combining with linguistic features and sentiment analysis

- Supervised Learning Classifiers:
  - Features include:
    - N-gram analysis
    - Vocabulary statistics
    - Syntactic patterns
    - Semantic coherence metrics
  - Common architectures:
    - Random Forests
    - Neural Networks
    - Transformers

- Zero-shot Detection:
  - DetectGPT approach:
    - Compares probability of original text with paraphrases
    - Higher original probability suggests AI generation
    - Achieved >95% accuracy in experiments

#### 4. Behavioral Analysis [blackbox]
- Tracks content creation patterns:
  - Typing rhythm
  - Keyboard-based biometrics
  - Editing patterns
  - Time spent on content creation

#### 5. Content Analysis Methods [blackbox]
- Semantic Consistency:
  - Analyzes logical flow and coherence
  - Checks factual consistency and argument structure
- Content Provenance:
  - Tracks content origin through metadata
- Retrieval-based Detection:
  - Compares against known AI-generated text database

#### Popular Tools
- DetectGPT: Token probability comparison (>95% accuracy)
- GPTZero: Perplexity and burstiness scoring
- ZipPy: Compression ratio analysis
- Commercial: 
  - CopyLeaks: Highest overall accuracy
  - GPTKit: Best for reducing false positives
  - GLTR: Most resilient across text types
  - Originality.AI

## Key Limitations

### Accuracy Issues (2023 Research)
- No tool exceeds 80% accuracy
- Only 5 of 14 tested tools achieve >70% accuracy
- High false-positive rates on human text
- Bias against non-native English writers

### Evasion Methods
- Paraphrasing reduces detection from 97% to 57%
- Anti-detection tools bypass systems
- Human editing further complicates detection
- Combined approaches (prompt engineering + paraphrasing) are particularly effective

### Technical Challenges
- Poor handling of:
  - Code detection
  - Non-English content
  - Edited/paraphrased text
- Tools show bias toward classifying text as human-written
- Limited generalization to new content types or domains

## References
- Wikipedia contributors. (2024). Artificial intelligence content detection. In Wikipedia. Retrieved from https://en.wikipedia.org/wiki/Artificial_intelligence_content_detection#Accuracy_issues
- The Register. (2023). Detecting AI-generated text is really hard, say computer scientists. Retrieved from https://www.theregister.com/2023/03/21/detecting_ai_generated_text/
- GPT Infinity Blog. (2024). Detecting AI: How to Check for AI Writing. Retrieved from https://blog.gptinf.com/detecting-ai-how-to-check-for-ai-writing
- Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., & Goldstein, T. (2023). A watermark for large language models. arXiv preprint arXiv:2301.10226
- Mitchell, E., Lee, Y., Khazatsky, A., Manning, C. D., & Finn, C. (2023). DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. arXiv preprint arXiv:2301.11156.
- Guo, Z., Geiping, J., Wen, Y., Goldstein, T., & Miers, I. (2023). Watermarking Text Data on Large Language Models for Dataset Attribution. arXiv preprint arXiv:2307.15593.
- Gu, Y., Zhu, X., Zhang, W., Yu, M., & Zhu, H. (2023). Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text. arXiv preprint arXiv:2310.14724.
- Gao, R., Chen, W., Liu, Z., Liu, X., & Zhao, D. (2023). Are LLM-Generated Text Detection Models Robust? A Comprehensive Analysis of Current Detection Systems. arXiv preprint arXiv:2310.15264.
- Kang, D., Luo, W., Zhang, T., & Duan, N. (2024). Deepfake Text Detection in the Wild: A Call for Watermarks and Stronger Baselines. arXiv preprint arXiv:2401.12070.
- Hou, Y., Liu, Z., Zhang, Y., & Zhang, M. (2023). Detecting AI-Generated Text: Current Status, Challenges, and Opportunities. arXiv preprint arXiv:2410.23746.
- Liyanage, C., Bharti, S. K., Chhaya, N., & Coghill, G. M. (2023). Detecting AI-generated text: a critical review of the state of the art. AI & Society. https://doi.org/10.1007/s40979-023-00146-z
- Weber-Wulff, D., et al. (2023). Evaluation of AI Text Detection Tools.
- MIT Technology Review. (2023). The AI Detection Arms Race.
- Eye Journal Study. (2023). Analysis of AI Detection Tools Against GPT-4 Generated Content.
- Communications of the ACM. (2024). The Science of Detecting LLM-Generated Text. Retrieved from https://cacm.acm.org/research/the-science-of-detecting-llm-generated-text/
- Betterprogramming Blog. (2024). Detecting LLM-Generated Texts. Retrieved from https://betterprogramming.pub/detecting-llm-generated-texts-befce4426da9
- Science of Detecting LLM-Generated Text. (2023). A comprehensive analysis of detection methods and challenges. arXiv preprint arXiv:2303.07205.
- Medium Article. (2024). The Science of Detecting LLM-Generated Texts. Retrieved from https://medium.com/@rxtang/the-science-of-detecting-llm-generated-texts-e816a14c18d
- GPTZero Blog. (2024). Inside GPTZero: AI Detection. Retrieved from https://gptzero.substack.com/p/inside-gptzero-ai-detection

# Further Look
https://huggingface.co/spaces/tomg-group-umd/lm-watermarking
https://github.com/jwkirchenbauer/lm-watermarking
https://github.com/NLP2CT/LLM-generated-Text-Detection?tab=readme-ov-file
https://huggingface.co/blog/dmicz/binoculars-text-detection
https://huggingface.co/spaces/SzegedAI/AI_Detector ** 

# Code examples
https://towardsdatascience.com/challenges-of-detecting-ai-generated-text-6d85bf779448#dc6a
Paper : AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising
https://github.com/beingamanforever/LLM-Text-Detection
https://github.com/thinkst/zippy
https://github.com/junchaoIU/GECScore
https://github.com/Vidhi1290/LLM---Detect-AI-Generated-Text 
https://github.com/IBM/RADAR
https://github.com/eric-mitchell/detect-gpt
https://github.com/BurhanUlTayyab/GPTZero
https://github.com/mbzuai-nlp/DetectLLM


# Models 
https://huggingface.co/SuperAnnotate/ai-detector
https://huggingface.co/openai-community/roberta-large-openai-detector
https://huggingface.co/microsoft/deberta-v3-base -> improved roberta
https://huggingface.co/spaces/SzegedAI/AI_Detector/blob/main/app.py
https://huggingface.co/answerdotai/ModernBERT-base -> to finetune

# Data Sets
https://huggingface.co/datasets/Ateeqq/AI-and-Human-Generated-Text
https://huggingface.co/datasets/artnitolog/llm-generated-texts
https://huggingface.co/datasets/dmitva/human_ai_generated_text
https://huggingface.co/datasets/Ateeqq/AI-and-Human-Generated-Text
https://huggingface.co/datasets/ura-hcmut/Generated-texts-Llama-2-7b-hf-reward_bench
https://huggingface.co/datasets/ura-hcmut/Generated-texts-Mistral-7B-v0.1-arc_challenge